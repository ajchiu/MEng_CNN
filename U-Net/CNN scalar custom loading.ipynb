{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749177ff-3ed3-4933-af1a-e96497bd2301",
   "metadata": {},
   "source": [
    "TODO: test batch size other than 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585941ef-25c1-463d-b168-39ce2b474ce1",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6061aa55-251b-4364-b330-988f655c4917",
   "metadata": {
    "id": "6061aa55-251b-4364-b330-988f655c4917",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import r2_score\n",
    "from BinvoxDataset import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
   "metadata": {
    "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
    "outputId": "124f3a64-fd41-43f6-8142-e776ca7c728a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
   "metadata": {
    "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
    "outputId": "d4ecf0c7-c798-41ef-9d25-e184eaf4aaf7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangli_824\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca78b2-c4d7-42d8-9892-f9208ea51be7",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab25529a-df30-4d60-8078-34ff66c2c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voxel downsampling code from chatGPT\n",
    "def condense_voxel_array(original_array, target_resolution):\n",
    "    ratio = original_array.shape[0] // target_resolution  # Assuming the array is cubic\n",
    "\n",
    "    condensed_array = np.zeros((target_resolution, target_resolution, target_resolution))\n",
    "\n",
    "    for x in range(0, original_array.shape[0], ratio):\n",
    "        for y in range(0, original_array.shape[1], ratio):\n",
    "            for z in range(0, original_array.shape[2], ratio):\n",
    "                # Calculate the average value for each group\n",
    "                average_value = np.mean(original_array[x:x+ratio, y:y+ratio, z:z+ratio])\n",
    "\n",
    "                # Store the average value in the condensed array\n",
    "                condensed_array[x // ratio, y // ratio, z // ratio] = average_value\n",
    "\n",
    "    return condensed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296f81a9-f655-43fd-b48e-2b321014569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(voxel):\n",
    "    # return torch.unsqueeze(torch.tensor(condense_voxel_array(voxel, 64), dtype = torch.float32), 0)\n",
    "    return torch.unsqueeze(torch.tensor(voxel, dtype = torch.float32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e2ce47-f930-4911-9852-d4aeeeac9e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "paths = json.load(open('config.json', 'r'))\n",
    "input_folder_path = paths['input_folder_path']\n",
    "label_file_path = paths['label_file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0521cd03-b614-41ce-9fb7-93d1c40393ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small values of max_count is for debugging and testing. Use max_count = None for full runs for training data.\n",
    "dataset = CustomDataset(input_folder_path = input_folder_path, label_file_path = label_file_path, transform = transform, max_count = None, ram_limit = 1000)\n",
    "dataset_limited = CustomDataset(input_folder_path = input_folder_path, label_file_path = label_file_path, transform = transform, max_count = 5000, ram_limit = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f42434-93ee-4923-9809-4aed63ddcce2",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2623ad-319a-4cb5-89cf-f279814a831e",
   "metadata": {
    "id": "8d2623ad-319a-4cb5-89cf-f279814a831e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, kernel_size = 3, activation_fn = nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_pooling_2 = nn.MaxPool3d(kernel_size = 2)\n",
    "\n",
    "        self.up_sampling_2 = nn.Upsample(scale_factor = 2)\n",
    "\n",
    "        self.conv64_1_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_8_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_8_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_32_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_32_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_128_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_128_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_256_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 256, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_384_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 384, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_160_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 160, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_40_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 40, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_8_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 1, kernel_size = kernel_size, padding = 'same'),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv64_1_8(x)\n",
    "        x = self.conv64_8_8(x)\n",
    "        feature_map_64 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv32_8_32(x)\n",
    "        x = self.conv32_32_32(x)\n",
    "        feature_map_32 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv16_32_128(x)\n",
    "        x = self.conv16_128_128(x)\n",
    "        feature_map_16 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv8_128_256(x)\n",
    "        x = self.conv8_256_256(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_16, x), dim = 1)\n",
    "        x = self.conv16_384_128(x)\n",
    "        x = self.conv16_128_128(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_32, x), dim = 1)\n",
    "        x = self.conv32_160_32(x)\n",
    "        x = self.conv32_32_32(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_64, x), dim = 1)\n",
    "        x = self.conv64_40_8(x)\n",
    "        x = self.conv64_8_1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d0082e-99dc-49ac-aa28-b190cfc76d48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNetScalarLabel(nn.Module):\n",
    "    def __init__(self, kernel_size = 3, activation_fn = nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_pooling_2 = nn.MaxPool3d(kernel_size = 2)\n",
    "        self.max_pooling_1 = nn.MaxPool3d(kernel_size = 1)\n",
    "        self.max_pooling_8 = nn.MaxPool3d(kernel_size = 8)\n",
    "        self.linear_1 = nn.Linear(256, 16)\n",
    "        self.linear_2 = nn.Linear(16, 1)\n",
    "\n",
    "        self.conv256_1_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 2, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 2),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv256_2_2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 2, out_channels = 2, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 2),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv128_2_4 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 2, out_channels = 4, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 4),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv128_4_4 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 4, out_channels = 4, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 4),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_1_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_4_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 4, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_8_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_8_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_32_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_32_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_128_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_128_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_256_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 256, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv4_256_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 256, out_channels = 32, kernel_size = 3, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv4_32_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 32, kernel_size = 3, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv2_32_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 1, kernel_size = 1, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 1),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Code for original (not downsampled) voxels\n",
    "        \n",
    "        x = self.conv256_1_2(x)\n",
    "        x = self.conv256_2_2(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv128_2_4(x)\n",
    "        x = self.conv128_4_4(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv64_4_8(x)\n",
    "        \n",
    "        \n",
    "        # Code for downsampled voxels\n",
    "        '''\n",
    "        x = self.conv64_1_8(x)\n",
    "        '''\n",
    "        \n",
    "        x = self.conv64_8_8(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv32_8_32(x)\n",
    "        x = self.conv32_32_32(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv16_32_128(x)\n",
    "        x = self.conv16_128_128(x)\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv8_128_256(x)\n",
    "        x = self.conv8_256_256(x)\n",
    "        x = self.max_pooling_8(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        # print('outcome shape', torch.squeeze(x).shape)\n",
    "        # return torch.reshape(x, (x.shape[0], 1))\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99138ba4-a9d8-4108-96da-6b503e54c7f1",
   "metadata": {},
   "source": [
    "# Define Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676a283b-9009-4ac8-8fd3-c1ef8b65c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_loader, optimizer, loss_fn):\n",
    "    cumulative_loss = 0.0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.squeeze(labels)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and its gradients\n",
    "        # print('label shape', labels.shape)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        cumulative_loss += loss.item()\n",
    "        \n",
    "        wandb.log({'batch loss': loss.item()})\n",
    "    return cumulative_loss / len(training_loader), cumulative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
   "metadata": {
    "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config, loss_fn):\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    # initialize a wandb run\n",
    "    wandb.init(config = config)\n",
    "\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    print('config:', config)\n",
    "\n",
    "    # get training loader\n",
    "    training_loader = DataLoader(dataset, batch_size = config.batch_size, shuffle = False)\n",
    "\n",
    "    # initialize model\n",
    "    if config.activation_fn == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    \n",
    "    if config.activation_fn == 'Sigmoid':\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    \n",
    "    model = ConvNetScalarLabel(kernel_size = config.kernel_size, activation_fn = activation_fn).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config.learning_rate, momentum = 0.9)\n",
    "\n",
    "    for epoch in range(config.epochs_choice):\n",
    "        avg_loss_per_batch, cumulative_loss = train_epoch(model, training_loader, optimizer, loss_fn)\n",
    "        wandb.log({'avg_loss_per_batch': avg_loss_per_batch, 'cumulative_loss': cumulative_loss})\n",
    "        print(f'Loss for epoch {epoch}: {cumulative_loss}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77c5334-2ce1-49ea-8785-c499da625081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config, model, loss_fn):\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # get testing loader\n",
    "    testing_loader = DataLoader(dataset_limited, batch_size = config.batch_size, shuffle = False)\n",
    "    \n",
    "    testing_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        testing_loss += loss.item()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy().tolist())\n",
    "        y_pred.extend(outputs.cpu().detach().numpy().tolist())\n",
    "    return testing_loss / len(testing_loader), testing_loss, r2_score(y_true = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45e5a4d-fe1f-4629-a456-1865f7e9906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(config = None):\n",
    "    loss_fn = nn.L1Loss()\n",
    "    model = train(config, loss_fn)\n",
    "    avg_loss_per_batch_test, testing_loss, r2 = test(config, model, loss_fn)\n",
    "    wandb.log({'avg_loss_per_batch_test': avg_loss_per_batch_test, 'testing_loss': testing_loss, 'r2': r2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3855e-1af6-4dac-a2eb-9afca254bdcd",
   "metadata": {},
   "source": [
    "# Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2403886e-355f-4658-8199-aebb835516bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'testing_loss',\n",
    "    'goal': 'minimize'\n",
    "    }\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'kernel_size': {\n",
    "        'values': [3, 4, 5]\n",
    "    },\n",
    "    'activation_fn': {\n",
    "        'values': ['ReLU', 'Sigmoid']\n",
    "    },\n",
    "    'epochs_choice': {\n",
    "          'values': [5, 10, 20]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'values': [1e-4, 1e-3, 1e-2]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [8, 4]\n",
    "    },\n",
    "}\n",
    "\n",
    "parameters_dict = {\n",
    "    'kernel_size': {\n",
    "        'values': [3]\n",
    "    },\n",
    "    'activation_fn': {\n",
    "        'values': ['ReLU']\n",
    "    },\n",
    "    'epochs_choice': {\n",
    "          'values': [5]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'values': [1e-3]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [4]\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411fe0-67e5-49c3-b22a-9d5ac1f5abd1",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f5fe4f-57a0-4445-aaec-58183fb12613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: k2wdd06b\n",
      "Sweep URL: https://wandb.ai/changli_824/CNN_sweep_scalar/sweeps/k2wdd06b\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project = 'CNN_sweep_scalar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8f8da-e378-4181-8bcc-fc83a0a26754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id = sweep_id, function = evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d71f0e-e630-4491-85ad-6182de3cd2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
